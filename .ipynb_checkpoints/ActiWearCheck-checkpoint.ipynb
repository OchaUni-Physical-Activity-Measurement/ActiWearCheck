{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a39126a",
   "metadata": {},
   "source": [
    "**[Log 31.10.2023]**  \n",
    "This code doesn't include an important step of checking and cleaning the physical activity data provided by Fitbit. For instance, the MET should be between 0<MET<18, there should be no duplicate or incorrect values in dates, etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c129dd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>oneStep</th>\n",
       "      <th>oneCalorie</th>\n",
       "      <th>DeviceName</th>\n",
       "      <th>measuredHR</th>\n",
       "      <th>dataLostSynch</th>\n",
       "      <th>Steps</th>\n",
       "      <th>Calories</th>\n",
       "      <th>Method1</th>\n",
       "      <th>Method2</th>\n",
       "      <th>Method3</th>\n",
       "      <th>MethodHR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-02-24</th>\n",
       "      <td>093.csv</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Alta HR</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>6852</td>\n",
       "      <td>2578.959183</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-25</th>\n",
       "      <td>093.csv</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Alta HR</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>7268</td>\n",
       "      <td>3022.053579</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-26</th>\n",
       "      <td>093.csv</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Alta HR</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>8966</td>\n",
       "      <td>2982.914397</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-27</th>\n",
       "      <td>093.csv</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Alta HR</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>12893</td>\n",
       "      <td>3411.029590</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-28</th>\n",
       "      <td>093.csv</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Alta HR</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>12964</td>\n",
       "      <td>3128.599201</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ID  oneStep  oneCalorie DeviceName  measuredHR  \\\n",
       "2023-02-24  093.csv     True        True    Alta HR        True   \n",
       "2023-02-25  093.csv     True        True    Alta HR        True   \n",
       "2023-02-26  093.csv     True        True    Alta HR        True   \n",
       "2023-02-27  093.csv     True        True    Alta HR        True   \n",
       "2023-02-28  093.csv     True        True    Alta HR        True   \n",
       "\n",
       "            dataLostSynch  Steps     Calories  Method1  Method2  Method3  \\\n",
       "2023-02-24          False   6852  2578.959183     True     True     True   \n",
       "2023-02-25          False   7268  3022.053579     True     True     True   \n",
       "2023-02-26          False   8966  2982.914397     True     True     True   \n",
       "2023-02-27          False  12893  3411.029590     True     True     True   \n",
       "2023-02-28          False  12964  3128.599201     True     True     True   \n",
       "\n",
       "            MethodHR  \n",
       "2023-02-24      True  \n",
       "2023-02-25      True  \n",
       "2023-02-26      True  \n",
       "2023-02-27      True  \n",
       "2023-02-28      True  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import date\n",
    "\n",
    "########## Definition of threshold values\n",
    "a = numberOfSteps = 1 #number of step to consider a day \n",
    "b = percentageDiffMinDay = 0.1 #percentage of difference between \"min-per-min data resampled by day\" and \"daily data\" to consider a day\n",
    "c = duration_of_PA_min = 600 #number of minutes per day above RMR\n",
    "d = duration_of_PA_hour = 10 #number of hours containing at least e minutes above RMR\n",
    "e = number_active_minutes = 1 #minutes\n",
    "f = number_of_steps = 3000 #number of steps in a day\n",
    "g = number_of_HR_hour = 10 #number of hours with HR data\n",
    "# Julien's add\n",
    "h = wakingHours = True\n",
    "\n",
    "########## Step one - Time serie cleaning procedure\n",
    "\n",
    "# 1- Import MINUTE data\n",
    "# Define the path where you have stored the Fitbit raw minute data (Steps, MET, Calories, Intensity)\n",
    "path_min = os.path.join(os.getcwd(),'samples/min')\n",
    "dict_min = {}\n",
    "for file_name in os.listdir(path_min):\n",
    "    if file_name.endswith(\".csv\"):  # we only import the .csv files\n",
    "        file_path = os.path.join(path_min, file_name)\n",
    "        columns_to_keep = ['Steps', 'Calories', 'ActivityMinute', 'ID']  # We are only interested in Steps and Calories here\n",
    "        df = pd.read_csv(file_path, usecols=columns_to_keep)\n",
    "        df = df.set_index('ActivityMinute')\n",
    "        df.index = pd.to_datetime(df.index)\n",
    "        \n",
    "        # Julien's add\n",
    "        if h:\n",
    "            df=df.between_time('5:00','22:59')\n",
    "        \n",
    "        df['RMR'] = df.resample('D')['Calories'].transform('min')  # Calculate the resting metabolic rate (RMR) = minute with the minimum Calorie value per day\n",
    "        key = file_name[:15] \n",
    "        df['ID'] = key\n",
    "        dict_min[key] = df\n",
    "\n",
    "# 2- Resample the minute data as daily\n",
    "dict_min_d = {}\n",
    "for key, df in dict_min.items():\n",
    "    # Calculate for each day the number of steps & calories\n",
    "    df_resampled = df.resample('D').agg({\n",
    "        'Steps': 'sum', \n",
    "        'Calories': 'sum',\n",
    "        'RMR': 'mean',\n",
    "        'ID': 'first'\n",
    "    })\n",
    "    df_resampled['dailyRMR'] = 1440 * df_resampled['RMR']  # Calculate the daily RMR = 1440 minute * RMR\n",
    "    dict_min_d[key] = df_resampled\n",
    "\n",
    "# 3- Import DAILY data\n",
    "# Define the path where you have stored the Fitbit raw daily data (Steps, MET, Calories, Intensity)\n",
    "path_day = os.path.join(os.getcwd(),'samples/day')\n",
    "dict_day = {}\n",
    "for file_name in os.listdir(path_day):\n",
    "    if file_name.endswith(\".csv\"):\n",
    "        file_path = os.path.join(path_day, file_name)\n",
    "        columns_to_keep = ['StepTotal', 'Calories', 'ActivityDay', 'ID']\n",
    "        df = pd.read_csv(file_path, usecols=columns_to_keep)\n",
    "\n",
    "        df = df.set_index('ActivityDay')\n",
    "        df.index = pd.to_datetime(df.index)\n",
    "        key = file_name[:15] \n",
    "        df['ID'] = key\n",
    "        dict_day[key] = df\n",
    "\n",
    "# 4- Estimate the record of at least one step during the day (or 1 calorie, not used in the manuscript)\n",
    "for key, df in dict_min_d.items():\n",
    "    df['oneStep'] = df['Steps'] >= numberOfSteps\n",
    "    condition = df['Calories'] > df['RMR'] # not used in the manuscript\n",
    "    df['oneCalorie'] = condition # not used in the manuscript\n",
    "    dict_min_d[key] = df \n",
    "\n",
    "# 5- Estimate the difference between minute data resampled by day\n",
    "columns_to_keep = ['Steps', 'Calories', 'ID', 'Date', 'oneStep', 'oneCalorie', 'diffMinDay']\n",
    "merged_dict = {}\n",
    "for key in dict_min_d.keys() & dict_day.keys():\n",
    "    df_min_d = dict_min_d[key]\n",
    "    df_day = dict_day[key]\n",
    "    # Merge minute data resampled by day ( suffix _m) with daily data (suffix _d)\n",
    "    merged_df = pd.concat([df_min_d.add_suffix('_m'), df_day.add_suffix('_d')], axis=1)\n",
    "    # Calculate the difference in steps and calories between minute data resampled by day with daily data\n",
    "    merged_df['diff_step'] = np.abs(merged_df['StepTotal_d'] - merged_df['Steps_m'])\n",
    "    merged_df['diff_cal'] = np.abs(merged_df['Calories_d'] - merged_df['Calories_m'])\n",
    "    # Determine if the difference is under the threshold\n",
    "    threshold_step = percentageDiffMinDay * merged_df['StepTotal_d'].mean()\n",
    "    threshold_cal = percentageDiffMinDay * merged_df['Calories_d'].mean()\n",
    "    merged_df['diff_step_ok'] = merged_df['diff_step'] < threshold_step\n",
    "    merged_df['diff_cal_ok'] = merged_df['diff_cal'] < threshold_cal\n",
    "    # Estimate if there is a difference for the day (diffMinDay column)\n",
    "    merged_df['diffMinDay'] = ~(merged_df['diff_step_ok'] & merged_df['diff_cal_ok'])\n",
    "    # Format the index as date and add the Date column\n",
    "    merged_df.index = pd.to_datetime(merged_df.index).strftime('%Y-%m-%d')\n",
    "    merged_df['Date'] = merged_df.index\n",
    "    # Ensure oneStep and oneCalorie columns are present in merged_df\n",
    "    merged_df['oneStep'] = df_min_d['oneStep']\n",
    "    merged_df['oneCalorie'] = df_min_d['oneCalorie']\n",
    "    # Keep  the necessary columns only, and rename them\n",
    "    final_df = merged_df[['StepTotal_d', 'Calories_d', 'ID_d', 'Date', 'oneStep', 'oneCalorie', 'diffMinDay']].copy()\n",
    "    final_df.columns = columns_to_keep\n",
    "    # Store the final DataFrame in the dictionary\n",
    "    merged_dict[key] = final_df\n",
    "\n",
    "########## Step two - estimation of valid wear\n",
    "\n",
    "#1- 3 different methods based on accelerometer data\n",
    "result_dict = {}\n",
    "for key, df in dict_min.items():\n",
    "    # Method 1: Days with valid wear required a minimum of 600 minutes above the estimated RMR\n",
    "    df_daily1 = df.resample('D').sum()\n",
    "    df_daily1['nMinAboveRMR'] = df[df['Calories'] > df['RMR']].resample('D').count()['Calories']\n",
    "    df_daily1['Method1'] = df_daily1['nMinAboveRMR'] >= duration_of_PA_min\n",
    "\n",
    "    # Method 2: Number of hours per days containing at least X active minutes\n",
    "    df['minAboveRMR'] = (df['Calories'] > df['RMR']).astype(int)\n",
    "    df['hourAboveRMR'] = df['minAboveRMR'].resample('h').sum() >= number_active_minutes\n",
    "    df_daily2 = df['hourAboveRMR'].resample('D').sum().to_frame()\n",
    "    df_daily2['Method2'] = df_daily2['hourAboveRMR'] >= duration_of_PA_hour\n",
    "\n",
    "    # Method 3: Number of steps per day (not used in the manuscript)\n",
    "    df_daily3 = df.resample('D').sum()\n",
    "    df_daily3['Method3'] = df_daily3['Steps'] >= number_of_steps # not used in the manuscript\n",
    "\n",
    "    # Concat all methods, and add them to the results\n",
    "    df_final = pd.concat([df_daily1['Method1'], df_daily2['Method2'], df_daily3['Method3']], axis=1)\n",
    "    df_final = df_final.rename_axis('Date')\n",
    "    result_dict[key] = df_final\n",
    "    \n",
    "for key, df in dict_min_d.items():\n",
    "    if key in result_dict:\n",
    "        result_df = result_dict[key]\n",
    "        final_df = pd.concat([df, result_df], axis=1)\n",
    "        dict_min_d[key] = final_df\n",
    "\n",
    "#2- One method based on HR data \n",
    "# (plus synchronisation and Device name informations from Fitbit)\n",
    "path_HR = os.path.join(os.getcwd(),'samples/HR')\n",
    "weartime_dict = {}\n",
    "syncevents_dict = {}\n",
    "syncevents_dict2 = {}\n",
    "deviceName_dict = {}\n",
    "diff_synch = {}\n",
    "for file in sorted(os.listdir(path_HR)):\n",
    "    if file.endswith(\".csv\"):\n",
    "        #importing the number of minutes with HR values\n",
    "        if \"WearTime\" in file:\n",
    "            key = file[:3]\n",
    "            if key not in weartime_dict:\n",
    "                weartime_dict[key] = []\n",
    "            file_path = os.path.join(path_HR, file)\n",
    "            df = pd.read_csv(file_path)\n",
    "\n",
    "            df[\"Day\"] = pd.to_datetime(df[\"Day\"])\n",
    "            df.set_index(\"Day\", inplace=True)\n",
    "            weartime_dict[key] = df\n",
    "        #importing the number of synchronisation per day (not used in the manuscript) and device name\n",
    "        if \"syncEvents\" in file:\n",
    "            key = file[:3]\n",
    "            if key not in syncevents_dict:\n",
    "                syncevents_dict[key] = []\n",
    "            file_path = os.path.join(path_HR, file)\n",
    "            df = pd.read_csv(file_path)\n",
    "\n",
    "            df[\"DateTime\"] = pd.to_datetime(df[\"DateTime\"])\n",
    "            df.set_index(\"DateTime\", inplace=True)\n",
    "            syncevents_dict2[key] = df\n",
    "            # Here we save the name of the device. As we only use the line 1, this can change over time\n",
    "            df_daily = df.groupby(df.index.date).first()\n",
    "            deviceName_dict[key] = df_daily['DeviceName']\n",
    "            # Here we count the number of synchronisations per day            \n",
    "            resampled_df = df['SyncDateUTC'].resample('D').count().rename(\"synchPerDay\")\n",
    "            syncevents_dict[key] = resampled_df\n",
    "concat_dict = {}\n",
    "for key in syncevents_dict:\n",
    "    if key in weartime_dict and key in deviceName_dict:\n",
    "        weartime_df = weartime_dict[key]\n",
    "        syncevents_df = syncevents_dict[key]\n",
    "        weartime_df['DeviceName'] = deviceName_dict[key]\n",
    "        concat_df = pd.concat([weartime_dict[key], syncevents_dict[key]], axis=1, join='inner')\n",
    "        concat_df = concat_df.assign(ID=key)\n",
    "        # DeviceName needs to be filled for missing dates\n",
    "        concat_df['DeviceName'] = concat_df['DeviceName'].fillna(method='ffill')\n",
    "        # Here we precise the memory length based on the model - set X based on DeviceName column: Alta = 5 days of memory, others = 7 days\n",
    "        concat_df['X'] = np.where(concat_df['DeviceName'] == 'Alta', -5, -7)\n",
    "        # MethodHR is TRUE if >= 10 hours of wearing time over the day (600 minutes with HR data)\n",
    "        concat_df['MethodHR'] = np.where(concat_df['TotalMinutesWearTime'] / 60 >= number_of_HR_hour, True, False)\n",
    "        # measuredHR is TRUE if any MethodHR is true for the subject (therefore, the watch was able to measure HR - and so contained an HR lens)\n",
    "        concat_df['measuredHR'] = concat_df['MethodHR'].any()\n",
    "\n",
    "        # not used in the manuscript\n",
    "        # SYNCH_FITBIT is TRUE if any synchronisation occured during the day\n",
    "        concat_df[\"SYNCH_FITBIT\"] = np.where(concat_df[\"synchPerDay\"] == 0, False, True)\n",
    "        # LASTSYNCH_D measures the number of days separating day n to the last day with SYNCH_FITBIT = TRUE        \n",
    "        concat_df['LASTSYNCH_D'] = pd.NaT\n",
    "        last_true_index = concat_df['SYNCH_FITBIT'].last_valid_index()\n",
    "        for index, row in concat_df.iterrows():\n",
    "            if row['SYNCH_FITBIT']:\n",
    "                concat_df.loc[index, 'LASTSYNCH_D'] = 0\n",
    "                last_true_index = index\n",
    "            elif last_true_index is not None:\n",
    "                concat_df.loc[index, 'LASTSYNCH_D'] = last_true_index - index\n",
    "                if concat_df.loc[index, 'LASTSYNCH_D'] != pd.Timedelta('0 days'):\n",
    "                    concat_df.loc[index, 'LASTSYNCH_D'] = concat_df.loc[index, 'LASTSYNCH_D'].days\n",
    "        # DATA_LOST is TRUE if LASTSYNCH_D > X\n",
    "        concat_df['LASTSYNCH_D'] = concat_df['LASTSYNCH_D'].astype(int)\n",
    "        concat_df['dataLostSynch'] = False\n",
    "        for index, row in concat_df.iterrows():\n",
    "            if row['LASTSYNCH_D'] <= row['X']:\n",
    "                index_to_update = concat_df.index.get_loc(index)\n",
    "                concat_df.at[concat_df.index[index_to_update], 'dataLostSynch'] = True\n",
    "        concat_df.drop(['ID', 'X'], axis=1, inplace=True)\n",
    "        concat_df['ID'] = key\n",
    "        concat_dict[key] = concat_df\n",
    "\n",
    "# merging all methods together\n",
    "dict_min_d_updated_keys = {key.split(\".\")[0]: value for key, value in dict_min_d.items()}\n",
    "for key in dict_min_d_updated_keys.keys() & concat_dict.keys():\n",
    "    df_min_d = dict_min_d_updated_keys[key]\n",
    "    # here we are only interested in MethodHR\n",
    "    df_concat = concat_dict[key][['DeviceName', 'MethodHR', 'measuredHR', 'dataLostSynch']]\n",
    "    # Convert indices to datetime if they aren't already\n",
    "    if not pd.api.types.is_datetime64_any_dtype(df_min_d.index):\n",
    "        df_min_d.index = pd.to_datetime(df_min_d.index)\n",
    "    if not pd.api.types.is_datetime64_any_dtype(df_concat.index):\n",
    "        df_concat.index = pd.to_datetime(df_concat.index)\n",
    "    # Ensure both DataFrames have the same index by taking the intersection of their indices\n",
    "    common_index = df_min_d.index.intersection(df_concat.index)\n",
    "    df_min_d = df_min_d.loc[common_index]\n",
    "    df_concat = df_concat.loc[common_index]\n",
    "    # Merge the DataFrames on their indices using concat with axis=1\n",
    "    merged_df = pd.concat([df_min_d, df_concat], axis=1)\n",
    "    # Only keep columns of interest for the manuscript\n",
    "    columns_to_keep = ['ID','oneStep',\t'oneCalorie', 'DeviceName',\t'measuredHR', 'dataLostSynch',\n",
    "                       'Steps',\t'Calories',\t\n",
    "                       'Method1','Method2','Method3','MethodHR']\n",
    "    merged_df = merged_df[columns_to_keep]\n",
    "    # Update dict_min_d with the merged DataFrame using the original key\n",
    "    dict_min_d[key + '.csv'] = merged_df\n",
    "\n",
    "##### Saving results (independently and all together)\n",
    "save_path = os.path.join(os.getcwd(),'results') #define here your path\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "all_dfs = []\n",
    "for key, df in dict_min_d.items():\n",
    "    df = df.reset_index().rename(columns={'index': 'Date'})\n",
    "    all_dfs.append(df)\n",
    "    file_path = os.path.join(save_path, f\"{key}.csv\")\n",
    "    df.to_csv(file_path, index=True)\n",
    "concatenated_df = pd.concat(all_dfs)\n",
    "concatenated_file_path = os.path.join(save_path, \"concatenated.csv\")\n",
    "concatenated_df.to_csv(concatenated_file_path, index=False)\n",
    "\n",
    "\n",
    "# Show participant 093 as example\n",
    "dict_min_d['093.csv'].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194cbaa8",
   "metadata": {},
   "source": [
    "From there, we can easily select days:\n",
    "- with at least one step recorded, \n",
    "- with at least one calories recorded, \n",
    "- with the correct device name used, recording HR,\n",
    "- with no data loss due to too sparse synchronisation (not used in the manuscript).  \n",
    "  \n",
    "After that, we can investigate, for each invididual and each day, the step count and the number of calories spend, depending on the method applyed:\n",
    "- method1: Days with valid wear required a minimum of 600 minutes above the estimated RMR\n",
    "- method2: Days with valid wear required a minimum of 10 hours containing at least 1 minute above the RMR\n",
    "- method3: Days with valid wear required a minimum of 3000 steps (not used in the manuscript)\n",
    "- methodHR: Days with valid wear required a minimum of 600 minutes with HR data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
