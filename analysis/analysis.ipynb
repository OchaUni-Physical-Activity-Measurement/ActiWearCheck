{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import itertools\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from scipy.stats import shapiro, friedmanchisquare, rankdata, ranksums\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "import pingouin as pg\n",
    "\n",
    "#0- import data & apply filters\n",
    "path_data = os.path.join(os.getcwd(), 'data.csv')\n",
    "df=pd.read_csv(path_data)\n",
    "df['Steps'] = df['Steps'].fillna(0).astype(int) #we are not interested in decimals\n",
    "df['Calories'] = df['Calories'].fillna(0).astype(int) #we are not interested in decimals\n",
    "df = df.drop('Unnamed: 0', axis=1)\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df = df.dropna(subset=['Date'])\n",
    "df = df.dropna(subset=['DeviceName'])\n",
    "df = df.set_index('Date')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of steps realised ('Steps') and calories spend ('Calories') for each day of observation ('Date') of each participant ('ID'). In addition, the data contains the filters applied: 1 step and 1 calories in the whole day ('oneStep' and 'oneCalorie'), difference between min-per-min and daily data ('dataLostSynch'), tracker with heart rate acquisition ('DeviceName' and 'measuredHR'). At last, the different filters for valid wear for each days based on our software ('Method1', 'Method2' and 'MethodHR')."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1- Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1- Number of days of observation per individual \n",
    "days_per_id = df.groupby('ID').size()\n",
    "weeks_per_id = days_per_id / 7\n",
    "mean_days = days_per_id.mean()\n",
    "std_days = days_per_id.std()\n",
    "mean_weeks = weeks_per_id.mean()\n",
    "std_weeks = weeks_per_id.std()\n",
    "\n",
    "print('Before any filters')\n",
    "print(f\"Number of days of observation per participants: {mean_days:.2f} +/- {std_days:.2f}\")\n",
    "print(f\"Number of weeks of observation per participants: {mean_weeks:.2f} +/- {std_weeks:.2f}\")\n",
    "print('')\n",
    "\n",
    "#2- Number of days and of participants considered depending on filters applied\n",
    "print(f\"Raw data: ..........................................{len(df)} days, {df['ID'].nunique()} participants\")\n",
    "print(df.describe().round(2))\n",
    "print('')\n",
    "# days measured with trackers containing HR lens, i.e. Alta HR or Inspire 2\n",
    "mask_device = (df['DeviceName'] == 'Alta HR') | (df['DeviceName'] == 'Inspire 2')\n",
    "df_filtered = df[mask_device]\n",
    "print(f\"Correct trackers (Alta HR or Inspire 2):...........{len(df_filtered)} days, {df_filtered['ID'].nunique()} participants\")\n",
    "print(df_filtered.describe().round(2))\n",
    "print('')\n",
    "# days with HR measured (HR lens not disabled)\n",
    "mask_hr_mesured = df_filtered['measuredHR'] == True\n",
    "df_filtered = df_filtered[mask_hr_mesured]\n",
    "print(f\"HR lens activated enabled:..........................{len(df_filtered)} days, {df_filtered['ID'].nunique()} participants\")\n",
    "print(df_filtered.describe().round(2))\n",
    "print('')\n",
    "# days with one step and one calorie reccorded\n",
    "mask_1step = df_filtered['oneStep'] & df_filtered['oneCalorie'] == True\n",
    "df_filtered = df_filtered[mask_1step]\n",
    "print(f\"One step and one calorie recorded:..................{len(df_filtered)} days, {df_filtered['ID'].nunique()} participants\")\n",
    "print(df_filtered.describe().round(2))\n",
    "print('')\n",
    "# days with no difference between min-per-min and daily data\n",
    "mask_diff = df_filtered['dataLostSynch'] == False\n",
    "df_filtered = df_filtered[mask_diff]\n",
    "print(f\"No difference between min-per-min and daily data: ...{len(df_filtered)} days, {df_filtered['ID'].nunique()} participants\")\n",
    "print(df_filtered.describe().round(2))\n",
    "print('')\n",
    "\n",
    "df_final = df_filtered\n",
    "\n",
    "# days with valid wear according to method1 \n",
    "mask_method1 = df_filtered['Method1'] == True\n",
    "df_filtered1 = df_filtered[mask_method1]\n",
    "print(f\"Valid wear according to method1:....................{len(df_filtered1)} days, {df_filtered1['ID'].nunique()} participants\")\n",
    "print(df_filtered1.describe().round(2))\n",
    "print('')\n",
    "# days with valid wear according to method2 \n",
    "mask_method2 = df_filtered['Method2'] == True\n",
    "df_filtered2 = df_filtered[mask_method2]\n",
    "print(f\"Valid wear according to method2:.....................{len(df_filtered2)} days, {df_filtered2['ID'].nunique()} participants\")\n",
    "print(df_filtered2.describe().round(2))\n",
    "print('')\n",
    "# days with valid wear according to methodHR \n",
    "mask_methodHR = df_filtered['MethodHR'] == True\n",
    "df_filteredHR = df_filtered[mask_methodHR]\n",
    "print(f\"Valid wear according to methodHR:....................{len(df_filteredHR)} days, {df_filteredHR['ID'].nunique()} participants\")\n",
    "print(df_filteredHR.describe().round(2))\n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2- Analytic Statistics\n",
    "## 2.1- Categorial approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1- Agreement rates\n",
    "\n",
    "validWearColumns = ['Method1', 'Method2']\n",
    "y_true = df_final['MethodHR'].astype(int)  # Convert boolean to binary (0 or 1)\n",
    "\n",
    "for column in validWearColumns:\n",
    "    y_pred = df_final[column].astype(int)  # Convert boolean to binary (0 or 1)\n",
    "    agreement_count = df_final[(y_true == 1) & (y_pred == 1)].shape[0]\n",
    "    total_count = df_final.shape[0]\n",
    "\n",
    "    # Agreement rate\n",
    "    agreement_rate = (agreement_count / total_count) * 100\n",
    "    print(f\" Between 'MethodHR' and '{column}' = {agreement_rate:.2f}%\")\n",
    "    print(f\"Agreement rate: {agreement_rate:.2f}%\")\n",
    "\n",
    "    # Accuracy, precision, recall, and F1-score\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    print(f\"Accuracy: {accuracy:.2f}\")\n",
    "    print(f\"Precision: {precision:.2f}\")\n",
    "    print(f\"Recall: {recall:.2f}\")\n",
    "    print(f\"F1-score: {f1:.2f}\")\n",
    "    print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2- Confusion matrix\n",
    "\n",
    "# First columns pair\n",
    "y_true_pair1 = df_final['MethodHR'].astype(int)  # Convert boolean to binary (0 or 1)\n",
    "y_pred_pair1 = df_final['Method1'].astype(int)  # Convert boolean to binary (0 or 1)\n",
    "cm_pair1 = confusion_matrix(y_true_pair1, y_pred_pair1)\n",
    "# Second columns pair\n",
    "y_true_pair2 = df_final['MethodHR'].astype(int)  # Convert boolean to binary (0 or 1)\n",
    "y_pred_pair2 = df_final['Method2'].astype(int)  # Convert boolean to binary (0 or 1)\n",
    "cm_pair2 = confusion_matrix(y_true_pair2, y_pred_pair2)\n",
    "# Numbers to percentages in cells\n",
    "cm_pair1_percent = cm_pair1 / cm_pair1.sum(axis=1)[:, np.newaxis] * 100\n",
    "cm_pair2_percent = cm_pair2 / cm_pair2.sum(axis=1)[:, np.newaxis] * 100\n",
    "cm_pair1_labels = np.array([f\"{value:.1f}%\\n({int(count)}/{int(total)})\"\n",
    "                            for value, count, total in zip(cm_pair1_percent.flatten(), cm_pair1.flatten(), cm_pair1.sum(axis=1).repeat(2))]).reshape(2,2)\n",
    "cm_pair2_labels = np.array([f\"{value:.1f}%\\n({int(count)}/{int(total)})\"\n",
    "                            for value, count, total in zip(cm_pair2_percent.flatten(), cm_pair2.flatten(), cm_pair2.sum(axis=1).repeat(2))]).reshape(2,2)\n",
    "\n",
    "# Ploting\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "# First matrix\n",
    "sns.heatmap(cm_pair1_percent, annot=cm_pair1_labels, fmt=\"\", cmap=\"Blues\", xticklabels=[\"Method 1 'invalid wear'\", \"Method 1 'valid wear'\"], \n",
    "            yticklabels=[\"Method HR 'invalid wear'\", \"Method HR 'valid wear'\"], ax=axes[0])\n",
    "axes[0].set_title(\"A. Method 1 vs Method HR\")\n",
    "\n",
    "# Second matrix\n",
    "sns.heatmap(cm_pair2_percent, annot=cm_pair2_labels, fmt=\"\", cmap=\"Blues\", xticklabels=[\"Method 2 'invalid wear'\", \"Method 2 'valid wear'\"], \n",
    "            yticklabels=[\"Method HR 'invalid wear'\", \"Method HR 'valid wear'\"], ax=axes[1])\n",
    "axes[1].set_title(\"B. Method 2 vs Method HR\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3- Distribution of disgreement according to the Steps and Calories values\n",
    "\n",
    "df = df_final.reset_index(drop=True)\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "def plot_histogram_with_disagreements(df, method1_col, methodHR_col, measure_col, ax, title):\n",
    "    df_disagreement = df[df[method1_col] != df[methodHR_col]]\n",
    "    df_agreement = df[df[method1_col] == df[methodHR_col]]\n",
    "    # Calculate statistical values for the measure with disagreements\n",
    "    q1_dis_val = df_disagreement[measure_col].quantile(0.25)\n",
    "    median_dis_val = df_disagreement[measure_col].median()\n",
    "    q3_dis_val = df_disagreement[measure_col].quantile(0.75)\n",
    "    # Histogram of the measure for agreements \n",
    "    ax.hist(df_agreement[measure_col], bins=20, edgecolor='k', alpha=0.5, label='Agreements')\n",
    "    # Histogram of the measure for disagreements\n",
    "    ax.hist(df_disagreement[measure_col], bins=20, edgecolor='k', alpha=0.7, label='Disagreements', color='orange')\n",
    "    # Add lines for quartiles and median for disagreements\n",
    "    # ax.axvline(q1_dis_val, color='b', linestyle='dashed', linewidth=2, label=f'Dis. Q1: {q1_dis_val}')\n",
    "    # ax.axvline(median_dis_val, color='r', linestyle='dashed', linewidth=2, label=f'Dis. Q2: {median_dis_val}')\n",
    "    # ax.axvline(q3_dis_val, color='m', linestyle='dashed', linewidth=2, label=f'Dis. Q3: {q3_dis_val}')\n",
    "    # Some adjustments\n",
    "    ax.set_xlabel(measure_col)\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.set_title(title)\n",
    "    ax.legend()\n",
    "    # ax.grid(True)\n",
    "\n",
    "plot_histogram_with_disagreements(df, 'Method1', 'MethodHR', 'Steps', axs[0, 0], 'Steps Method1 vs MethodHR')\n",
    "plot_histogram_with_disagreements(df, 'Method2', 'MethodHR', 'Steps', axs[0, 1], 'Steps Method2 vs MethodHR')\n",
    "plot_histogram_with_disagreements(df, 'Method1', 'MethodHR', 'Calories', axs[1, 0], 'Calories Method1 vs MethodHR')\n",
    "plot_histogram_with_disagreements(df, 'Method2', 'MethodHR', 'Calories', axs[1, 1], 'Calories Method2 vs MethodHR')\n",
    "\n",
    "plt.suptitle('Distributions of daily mean Steps and Calories values - Agreement and Disagreement between Methods', fontsize=16)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3- Distribution analysis - day wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3- Distribution analysis - all days and all participants together\n",
    "df_anova = df_final[['ID', 'Steps', 'Calories', 'Method1', 'Method2', 'MethodHR']].copy()\n",
    "\n",
    "model_steps = ols('Steps ~ C(Method1) * C(Method2) * C(MethodHR)', data=df_anova).fit()\n",
    "anova_table_steps = sm.stats.anova_lm(model_steps, typ=2)\n",
    "\n",
    "model_calories = ols('Calories ~ C(Method1) * C(Method2) * C(MethodHR)', data=df_anova).fit()\n",
    "anova_table_calories = sm.stats.anova_lm(model_calories, typ=2)\n",
    "\n",
    "print(\"ANOVA for Steps :\")\n",
    "print(anova_table_steps)\n",
    "print('')\n",
    "print(\"ANOVA for Calories :\")\n",
    "print(anova_table_calories)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found no effect of the method applied (1,2 or HR) on Steps (p = 0.534521) nor Calories (p = 0.662464). This may be due to high differences between subjects. We therefore go with a subject-wise analysis.\n",
    "\n",
    "## 2.4- Distribution analysis - subject wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4- Distribution analysis - mean daily physical activity, subject wise\n",
    "\n",
    "def mean_steps_by_method(x, method_col):\n",
    "    return x.loc[x[method_col] == 1, 'Steps'].mean()\n",
    "\n",
    "def mean_calories_by_method(x, method_col):\n",
    "    return x.loc[x[method_col] == 1, 'Calories'].mean()\n",
    "\n",
    "grouped = df_final.groupby('ID').apply(lambda x: pd.Series({\n",
    "    'StepsMethod1': mean_steps_by_method(x, 'Method1'),\n",
    "    'StepsMethod2': mean_steps_by_method(x, 'Method2'),\n",
    "    'StepsMethodHR': mean_steps_by_method(x, 'MethodHR'),\n",
    "    'StepsAll': x['Steps'].mean(),\n",
    "    'CaloriesMethod1': mean_calories_by_method(x, 'Method1'),\n",
    "    'CaloriesMethod2': mean_calories_by_method(x, 'Method2'),\n",
    "    'CaloriesMethodHR': mean_calories_by_method(x, 'MethodHR'),\n",
    "    'CaloriesAll': x['Calories'].mean()\n",
    "})).reset_index()\n",
    "\n",
    "num_days_observation = df_final.groupby('ID').size().reset_index(name='numDays')\n",
    "grouped = grouped.merge(num_days_observation, on='ID', how='left')\n",
    "grouped.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean daily number of steps realised ('Steps') and calories spend ('Calories') for each each participant ('ID') depending on the method applied ('Method1', 'Method2', 'MethodHR', or no method 'All'), as well as number of days considered ('numDays'). \n",
    "\n",
    "  \n",
    "Subject 040 has only 1 day of observation, and so NaN as steps and calories values with different methods. This is because this subject started the experiment with a Fitbit Alta, and changed for an Alta HR late (5 days of observation). All these days contained an issue of synching, wearing etc. We therefore suppress this subject in further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = grouped[grouped['ID'] != '040']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the figure and axes\n",
    "fig, axs = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Bland-Altman plot for Steps (Method1 vs MethodHR)\n",
    "pg.plot_blandaltman(df_cleaned['StepsMethod1'], df_cleaned['StepsMethodHR'], ax=axs[0, 0])\n",
    "axs[0, 0].set_title('Steps (Method1 vs MethodHR)')\n",
    "\n",
    "# Bland-Altman plot for Steps (Method2 vs MethodHR)\n",
    "pg.plot_blandaltman(df_cleaned['StepsMethod2'], df_cleaned['StepsMethodHR'], ax=axs[0, 1])\n",
    "axs[0, 1].set_title('Steps (Method2 vs MethodHR)')\n",
    "\n",
    "# Bland-Altman plot for Calories (Method1 vs MethodHR)\n",
    "pg.plot_blandaltman(df_cleaned['CaloriesMethod1'], df_cleaned['CaloriesMethodHR'], ax=axs[1, 0])\n",
    "axs[1, 0].set_title('Calories (Method1 vs MethodHR)')\n",
    "\n",
    "# Bland-Altman plot for Calories (Method2 vs MethodHR)\n",
    "pg.plot_blandaltman(df_cleaned['CaloriesMethod2'], df_cleaned['CaloriesMethodHR'], ax=axs[1, 1])\n",
    "axs[1, 1].set_title('Calories (Method2 vs MethodHR)')\n",
    "\n",
    "# General plot settings\n",
    "plt.suptitle('Differences between Method1 and Method2 vs MethodHR for stepcount and calories', fontsize=16)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This figure is presented in a different maner in the paper manuscript."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test for distribution normality\n",
    "columns_to_test = ['StepsMethod1', 'StepsMethod2', 'StepsMethodHR', 'StepsAll',\n",
    "                   'CaloriesMethod1', 'CaloriesMethod2', 'CaloriesMethodHR', 'CaloriesAll']\n",
    "\n",
    "shapiro_results = {}\n",
    "for col in columns_to_test:\n",
    "    stat, p_value = shapiro(df_cleaned[col].dropna())\n",
    "    shapiro_results[col] = (stat, p_value)\n",
    "\n",
    "for col, (stat, p_value) in shapiro_results.items():\n",
    "    print(f'Column: {col}, Statistic: {stat:.4f}, p-value: {p_value:.4f}')\n",
    "    if p_value > 0.05:\n",
    "        print(f'   Normality distribution for data in {col} (p > 0.05).')\n",
    "    else:\n",
    "        print(f'   NON-normality distribution for data in {col}  (p â‰¤ 0.05).')\n",
    "    print('---')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the distribution for Calories value are non normal, we apply a non-parametric test for differences in Steps and Calories distribution between methods 1, 2 and HR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Friedman test - global effect\n",
    "def test_method_effect_global(df, variable):\n",
    "    print(f\"Effect of methods on {variable}:\")\n",
    "    columns = [f\"{variable}Method1\", f\"{variable}Method2\", f\"{variable}MethodHR\", f\"{variable}All\"]\n",
    "    try:\n",
    "        df_filtered = df.dropna(subset=columns)\n",
    "        stat, p_value = friedmanchisquare(df_filtered[columns[0]], df_filtered[columns[1]], df_filtered[columns[2]])\n",
    "        print(f\"Friedman Test for {variable}: Statistic={stat:.2f}, p-value={p_value:.4f}\")\n",
    "        if p_value < 0.05:\n",
    "            print(\"Reject null hypothesis: There is a significant difference between methods.\")\n",
    "        else:\n",
    "            print(\"Fail to reject null hypothesis: No significant difference between methods.\")\n",
    "        print()\n",
    "    except KeyError as e:\n",
    "        print(f\"Error: One or more columns {e} not found in DataFrame.\")\n",
    "\n",
    "print('->Friedman global effect of Method (1x2xHR) on Steps and Calories')\n",
    "test_method_effect_global(df_cleaned, 'Steps')\n",
    "test_method_effect_global(df_cleaned, 'Calories')\n",
    "print('===============================')\n",
    "\n",
    "# Conover post hoc test\n",
    "def test_post_hoc_conover(df, variable):\n",
    "    columns = [f\"{variable}Method1\", f\"{variable}Method2\", f\"{variable}MethodHR\", f\"{variable}All\"]    \n",
    "    df_filtered = df.dropna(subset=columns)\n",
    "    # rank calculation\n",
    "    ranks = df_filtered[columns].apply(rankdata, axis=1) #rank calculation\n",
    "    mean_ranks = ranks.mean()\n",
    "    print(f\"Mean Ranks for {variable}:\")\n",
    "    print(mean_ranks)\n",
    "    print()\n",
    "    # pairs comparison\n",
    "    pairs = list(itertools.combinations(columns, 2))\n",
    "    for pair in pairs:\n",
    "        print(f\"Comparing {pair[0]} vs {pair[1]}:\")\n",
    "        stat, p_value = ranksums(df_filtered[pair[0]], df_filtered[pair[1]])\n",
    "        print(f\"Ranksums Test (Conover) for {pair[0]} vs {pair[1]}: Statistic={stat:.4f}, p-value={p_value:.4f}\")\n",
    "        if p_value < 0.05:\n",
    "            print(\"Reject null hypothesis: There is a significant difference between methods.\")\n",
    "        else:\n",
    "            print(\"Fail to reject null hypothesis: No significant difference between methods.\")\n",
    "        print()\n",
    "\n",
    "print('->Conover post-hoc test for pair-wise methods comparison')\n",
    "test_post_hoc_conover(df_cleaned, 'Steps')\n",
    "print('-------------------------')\n",
    "test_post_hoc_conover(df_cleaned, 'Calories')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a subject-wise approach, we found that the method applied (1, 2 or HR) have a global impact on the daily mean step count and calories spend values. Post-hoc tests showed that the pair-wise difference is statistically significant between methods 1 and 2 for steps. The rest of difference is due to global distribution differences. We represent this with a boxplot figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graphical illustration\n",
    "df_steps = pd.melt(df_cleaned, id_vars='ID', value_vars=['StepsMethod1', 'StepsMethod2', 'StepsMethodHR', 'StepsAll'], var_name='Method', value_name='Value_Steps')\n",
    "df_calories = pd.melt(df_cleaned, id_vars='ID', value_vars=['CaloriesMethod1', 'CaloriesMethod2', 'CaloriesMethodHR', 'CaloriesAll'], var_name='Method', value_name='Value_Calories')\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(12, 10))\n",
    "\n",
    "palette_steps = sns.color_palette(['#fff8c7', '#ffe8b8', '#ffb361', '#ff8e24'])  \n",
    "palette_calories = sns.color_palette(['#fec4ff', '#E8AABE', '#DB6A8F', '#CA3C66'])  \n",
    "\n",
    "#Steps\n",
    "sns.boxplot(x='Method', y='Value_Steps', data=df_steps, ax=axes[0], palette=palette_steps)\n",
    "#axes[0].set_title('Mean daily physical activity parameters distribution comparison between 3 methods and original data', fontsize=14, weight='bold')\n",
    "axes[0].set_xlabel(' ', fontsize=12)\n",
    "#axes[0].set_ylabel('daily step-count per participants', fontsize=12)\n",
    "axes[0].set_ylabel('daily number of steps (step/d)', fontsize=12)\n",
    "axes[0].set_ylim(3000, 27000)\n",
    "axes[0].set_xticklabels([' ', ' ', ' ',' '])\n",
    "\n",
    "\n",
    "#Calories\n",
    "sns.boxplot(x='Method', y='Value_Calories', data=df_calories, ax=axes[1], palette=palette_calories)\n",
    "axes[1].set_xlabel(' ', fontsize=12)\n",
    "#axes[1].set_ylabel('daily calories per participants', fontsize=12)\n",
    "axes[1].set_ylabel('daily energy expenditure (kcal/d)', fontsize=12)\n",
    "axes[1].set_ylim(2000, 5500)\n",
    "axes[1].set_xticklabels(['Method 1', 'Method 2', 'Method HR', \"No Method\"])\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.savefig(\"figure 4.png\", dpi='figure')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(f'N participants={len(df_cleaned)}')\n",
    "mean_num_days = grouped['numDays'].mean()\n",
    "print(f'N mean number of days merged = {mean_num_days.round(1)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Illustration with one participant\n",
    "Here, we illustrate the impact of our different methods (1, 2 and HR) on the number of days retained and Steps reccorded in one participant (ID = 056)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_df = df[df['ID'] == '056']\n",
    "\n",
    "all_days = subset_df\n",
    "conditionOneStep = subset_df['oneStep'] == True\n",
    "conditionOneCalorie= subset_df['oneCalorie'] == True\n",
    "conditionNoDiff = subset_df['dataLostSynch'] == False\n",
    "considered = subset_df[conditionOneStep & conditionOneCalorie & conditionNoDiff].copy()\n",
    "\n",
    "methodHR = considered[considered['MethodHR'] == True][['Steps']].copy()\n",
    "method1 = considered[considered['Method1'] == True][['Steps']].copy()\n",
    "method2 = considered[considered['Method2'] == True][['Steps']].copy()\n",
    "\n",
    "fig, axs = plt.subplots(4, 1, figsize=(10, 15), sharex=True)\n",
    "\n",
    "# All days considered\n",
    "mean_all_days = all_days['Steps'].mean()\n",
    "std_all_days = all_days['Steps'].std()\n",
    "axs[0].bar(all_days.index, all_days['Steps'], label='All Days considered')\n",
    "axs[0].legend()\n",
    "axs[0].set_ylabel('Steps')\n",
    "axs[0].annotate(f\"Number of days considered : {len(all_days)}\\nMean steps per day: {round(mean_all_days)} +/- {round(std_all_days)}\",\n",
    "                xy=(0.5, 1.05), xycoords='axes fraction', ha='center', va='center')\n",
    "\n",
    "# Method1\n",
    "mean_method1 = method1['Steps'].mean()\n",
    "std_method1 = method1['Steps'].std()\n",
    "axs[1].bar(method1.index, method1['Steps'], label='Method 1', color='#0000FF')\n",
    "axs[1].legend()\n",
    "axs[1].set_ylabel('Steps')\n",
    "axs[1].annotate(f\"Number of days considered : {len(method1)}\\nMean steps per day: {round(mean_method1)} +/- {round(std_method1)}\",\n",
    "                xy=(0.5, 1.05), xycoords='axes fraction', ha='center', va='center')\n",
    "\n",
    "# Method2\n",
    "mean_method2 = method2['Steps'].mean()\n",
    "std_method2 = method2['Steps'].std()\n",
    "axs[2].bar(method2.index, method2['Steps'], label='Method 2', color='#004d00')\n",
    "axs[2].legend()\n",
    "axs[2].set_ylabel('Steps')\n",
    "axs[2].annotate(f\"Number of days considered : {len(method2)}\\nMean steps per day: {round(mean_method2)} +/- {round(std_method2)}\",\n",
    "                xy=(0.5, 1.05), xycoords='axes fraction', ha='center', va='center')\n",
    "\n",
    "# MethodHR\n",
    "mean_methodHR = methodHR['Steps'].mean()\n",
    "std_methodHR = methodHR['Steps'].std()\n",
    "axs[3].bar(methodHR.index, methodHR['Steps'], label='Method HR', color='#FF4500')\n",
    "axs[3].legend()\n",
    "axs[3].set_xlabel('Date')\n",
    "axs[3].set_ylabel('Steps')\n",
    "axs[3].annotate(f\"Number of days considered : {len(methodHR)}\\nMean steps per day: {round(mean_methodHR)} +/- {round(std_methodHR)}\",\n",
    "                xy=(0.5, 1.05), xycoords='axes fraction', ha='center', va='center')\n",
    "\n",
    "for ax in axs.flat:\n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
